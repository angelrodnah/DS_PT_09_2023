[
    {
        "label": "openmeteo_requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "openmeteo_requests",
        "description": "openmeteo_requests",
        "detail": "openmeteo_requests",
        "documentation": {}
    },
    {
        "label": "requests_cache",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests_cache",
        "description": "requests_cache",
        "detail": "requests_cache",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "retry",
        "importPath": "retry_requests",
        "description": "retry_requests",
        "isExtraImport": true,
        "detail": "retry_requests",
        "documentation": {}
    },
    {
        "label": "LooseVersion",
        "importPath": "distutils.version",
        "description": "distutils.version",
        "isExtraImport": true,
        "detail": "distutils.version",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "ListedColormap",
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "isExtraImport": true,
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "ListedColormap",
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "isExtraImport": true,
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "FormatStrFormatter",
        "importPath": "matplotlib.ticker",
        "description": "matplotlib.ticker",
        "isExtraImport": true,
        "detail": "matplotlib.ticker",
        "documentation": {}
    },
    {
        "label": "PercentFormatter",
        "importPath": "matplotlib.ticker",
        "description": "matplotlib.ticker",
        "isExtraImport": true,
        "detail": "matplotlib.ticker",
        "documentation": {}
    },
    {
        "label": "stock_analysis",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "stock_analysis",
        "description": "stock_analysis",
        "detail": "stock_analysis",
        "documentation": {}
    },
    {
        "label": "pkg_resources",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pkg_resources",
        "description": "pkg_resources",
        "detail": "pkg_resources",
        "documentation": {}
    },
    {
        "label": "Ellipse",
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "isExtraImport": true,
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "auc",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "auc",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "scipy.stats",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "bernoulli",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "binom",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "expon",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "poisson",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "norm",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "skewnorm",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "skew",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "kurtosis",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "shapiro",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "iqr",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "kurtosis",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "skew",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "norm",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "uniform",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "ECDF",
        "importPath": "statsmodels.distributions.empirical_distribution",
        "description": "statsmodels.distributions.empirical_distribution",
        "isExtraImport": true,
        "detail": "statsmodels.distributions.empirical_distribution",
        "documentation": {}
    },
    {
        "label": "seasonal_decompose",
        "importPath": "statsmodels.tsa.seasonal",
        "description": "statsmodels.tsa.seasonal",
        "isExtraImport": true,
        "detail": "statsmodels.tsa.seasonal",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "distutils.core",
        "description": "distutils.core",
        "isExtraImport": true,
        "detail": "distutils.core",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "render_template",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "load_iris",
        "importPath": "sklearn.datasets",
        "description": "sklearn.datasets",
        "isExtraImport": true,
        "detail": "sklearn.datasets",
        "documentation": {}
    },
    {
        "label": "KNeighborsClassifier",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_predict",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "RandomizedSearchCV",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "BorutaShap",
        "importPath": "BorutaShap",
        "description": "BorutaShap",
        "isExtraImport": true,
        "detail": "BorutaShap",
        "documentation": {}
    },
    {
        "label": "statsmodels.api",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "statsmodels.api",
        "description": "statsmodels.api",
        "detail": "statsmodels.api",
        "documentation": {}
    },
    {
        "label": "OneVsRestClassifier",
        "importPath": "sklearn.multiclass",
        "description": "sklearn.multiclass",
        "isExtraImport": true,
        "detail": "sklearn.multiclass",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "stats",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "ingresos",
        "kind": 5,
        "importPath": "01-Ramp_Up.02-Python.01-Python.1-Basics.Teoria.a",
        "description": "01-Ramp_Up.02-Python.01-Python.1-Basics.Teoria.a",
        "peekOfCode": "ingresos = 1000\nprint(ingresos)\ningresos = 500\nprint(ingresos)\nprint('\"hola\"')",
        "detail": "01-Ramp_Up.02-Python.01-Python.1-Basics.Teoria.a",
        "documentation": {}
    },
    {
        "label": "ingresos",
        "kind": 5,
        "importPath": "01-Ramp_Up.02-Python.01-Python.1-Basics.Teoria.a",
        "description": "01-Ramp_Up.02-Python.01-Python.1-Basics.Teoria.a",
        "peekOfCode": "ingresos = 500\nprint(ingresos)\nprint('\"hola\"')",
        "detail": "01-Ramp_Up.02-Python.01-Python.1-Basics.Teoria.a",
        "documentation": {}
    },
    {
        "label": "c",
        "kind": 5,
        "importPath": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.otro_folder.segundo_script_2",
        "description": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.otro_folder.segundo_script_2",
        "peekOfCode": "c = 3\nd = 4",
        "detail": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.otro_folder.segundo_script_2",
        "documentation": {}
    },
    {
        "label": "d",
        "kind": 5,
        "importPath": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.otro_folder.segundo_script_2",
        "description": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.otro_folder.segundo_script_2",
        "peekOfCode": "d = 4",
        "detail": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.otro_folder.segundo_script_2",
        "documentation": {}
    },
    {
        "label": "c",
        "kind": 5,
        "importPath": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.segundo_script",
        "description": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.segundo_script",
        "peekOfCode": "c = 3\nd = 4",
        "detail": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.segundo_script",
        "documentation": {}
    },
    {
        "label": "d",
        "kind": 5,
        "importPath": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.segundo_script",
        "description": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.segundo_script",
        "peekOfCode": "d = 4",
        "detail": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.direc_segundo.segundo_script",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.ejer_prueba",
        "description": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.ejer_prueba",
        "peekOfCode": "a = 1\nb = 2",
        "detail": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.ejer_prueba",
        "documentation": {}
    },
    {
        "label": "b",
        "kind": 5,
        "importPath": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.ejer_prueba",
        "description": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.ejer_prueba",
        "peekOfCode": "b = 2",
        "detail": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.ejer_prueba",
        "documentation": {}
    },
    {
        "label": "MyClass",
        "kind": 6,
        "importPath": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.primer_script",
        "description": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.primer_script",
        "peekOfCode": "class MyClass:\n    \"\"\"\n    Example class.\n    \"\"\"\n    def __init__(self):\n        self.variable = my_variable\n    def set_variable(self, new_value: int) -> None:\n        \"\"\"\n        Set self.variable to a new value\n        \"\"\"",
        "detail": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.primer_script",
        "documentation": {}
    },
    {
        "label": "my_function",
        "kind": 2,
        "importPath": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.primer_script",
        "description": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.primer_script",
        "peekOfCode": "def my_function() -> int:\n    \"\"\"\n    Example function\n    \"\"\"\n    return my_variable\nclass MyClass:\n    \"\"\"\n    Example class.\n    \"\"\"\n    def __init__(self):",
        "detail": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.primer_script",
        "documentation": {}
    },
    {
        "label": "my_variable",
        "kind": 5,
        "importPath": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.primer_script",
        "description": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.primer_script",
        "peekOfCode": "my_variable = 0\ndef my_function() -> int:\n    \"\"\"\n    Example function\n    \"\"\"\n    return my_variable\nclass MyClass:\n    \"\"\"\n    Example class.\n    \"\"\"",
        "detail": "01-Ramp_Up.02-Python.01-Python.6-Modules.Teoria.primer_script",
        "documentation": {}
    },
    {
        "label": "circle_areas",
        "kind": 5,
        "importPath": "01-Ramp_Up.02-Python.01-Python.7-Programacion funcional.Teoría.prueba",
        "description": "01-Ramp_Up.02-Python.01-Python.7-Programacion funcional.Teoría.prueba",
        "peekOfCode": "circle_areas = [3.56773, 5.57668, 4.00914, 56.24241, 9.01344, 32.00013]\nresult = map(round, circle_areas)\n# print(list(result))\nprint(tuple(result))",
        "detail": "01-Ramp_Up.02-Python.01-Python.7-Programacion funcional.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "01-Ramp_Up.02-Python.01-Python.7-Programacion funcional.Teoría.prueba",
        "description": "01-Ramp_Up.02-Python.01-Python.7-Programacion funcional.Teoría.prueba",
        "peekOfCode": "result = map(round, circle_areas)\n# print(list(result))\nprint(tuple(result))",
        "detail": "01-Ramp_Up.02-Python.01-Python.7-Programacion funcional.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "cache_session",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\nretry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\nopenmeteo = openmeteo_requests.Client(session = retry_session)\n# Make sure all required weather variables are listed here\n# The order of variables in hourly or daily is important to assign them correctly below\nurl = \"https://archive-api.open-meteo.com/v1/archive\"\nparams = {\n\t\"latitude\": 52.52,\n\t\"longitude\": 13.41,\n\t\"start_date\": \"2000-12-31\",",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "retry_session",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\nopenmeteo = openmeteo_requests.Client(session = retry_session)\n# Make sure all required weather variables are listed here\n# The order of variables in hourly or daily is important to assign them correctly below\nurl = \"https://archive-api.open-meteo.com/v1/archive\"\nparams = {\n\t\"latitude\": 52.52,\n\t\"longitude\": 13.41,\n\t\"start_date\": \"2000-12-31\",\n\t\"end_date\": \"2019-12-31\",",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "openmeteo",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "openmeteo = openmeteo_requests.Client(session = retry_session)\n# Make sure all required weather variables are listed here\n# The order of variables in hourly or daily is important to assign them correctly below\nurl = \"https://archive-api.open-meteo.com/v1/archive\"\nparams = {\n\t\"latitude\": 52.52,\n\t\"longitude\": 13.41,\n\t\"start_date\": \"2000-12-31\",\n\t\"end_date\": \"2019-12-31\",\n\t\"hourly\": [\"temperature_2m\", \"precipitation\", \"rain\"]",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "url = \"https://archive-api.open-meteo.com/v1/archive\"\nparams = {\n\t\"latitude\": 52.52,\n\t\"longitude\": 13.41,\n\t\"start_date\": \"2000-12-31\",\n\t\"end_date\": \"2019-12-31\",\n\t\"hourly\": [\"temperature_2m\", \"precipitation\", \"rain\"]\n}\nresponses = openmeteo.weather_api(url, params=params)\n# Process first location. Add a for-loop for multiple locations or weather models",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "params",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "params = {\n\t\"latitude\": 52.52,\n\t\"longitude\": 13.41,\n\t\"start_date\": \"2000-12-31\",\n\t\"end_date\": \"2019-12-31\",\n\t\"hourly\": [\"temperature_2m\", \"precipitation\", \"rain\"]\n}\nresponses = openmeteo.weather_api(url, params=params)\n# Process first location. Add a for-loop for multiple locations or weather models\nresponse = responses[0]",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "responses",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "responses = openmeteo.weather_api(url, params=params)\n# Process first location. Add a for-loop for multiple locations or weather models\nresponse = responses[0]\nprint(f\"Coordinates {response.Latitude()}°E {response.Longitude()}°N\")\nprint(f\"Elevation {response.Elevation()} m asl\")\nprint(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\nprint(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n# Process hourly data. The order of variables needs to be the same as requested.\nhourly = response.Hourly()\nhourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "response = responses[0]\nprint(f\"Coordinates {response.Latitude()}°E {response.Longitude()}°N\")\nprint(f\"Elevation {response.Elevation()} m asl\")\nprint(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\nprint(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n# Process hourly data. The order of variables needs to be the same as requested.\nhourly = response.Hourly()\nhourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\nhourly_precipitation = hourly.Variables(1).ValuesAsNumpy()\nhourly_rain = hourly.Variables(2).ValuesAsNumpy()",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "hourly",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "hourly = response.Hourly()\nhourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\nhourly_precipitation = hourly.Variables(1).ValuesAsNumpy()\nhourly_rain = hourly.Variables(2).ValuesAsNumpy()\nhourly_data = {\"date\": pd.date_range(\n\tstart = pd.to_datetime(hourly.Time(), unit = \"s\"),\n\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\"),\n\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n\tinclusive = \"left\"\n)}",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "hourly_temperature_2m",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\nhourly_precipitation = hourly.Variables(1).ValuesAsNumpy()\nhourly_rain = hourly.Variables(2).ValuesAsNumpy()\nhourly_data = {\"date\": pd.date_range(\n\tstart = pd.to_datetime(hourly.Time(), unit = \"s\"),\n\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\"),\n\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n\tinclusive = \"left\"\n)}\nhourly_data[\"temperature_2m\"] = hourly_temperature_2m",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "hourly_precipitation",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "hourly_precipitation = hourly.Variables(1).ValuesAsNumpy()\nhourly_rain = hourly.Variables(2).ValuesAsNumpy()\nhourly_data = {\"date\": pd.date_range(\n\tstart = pd.to_datetime(hourly.Time(), unit = \"s\"),\n\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\"),\n\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n\tinclusive = \"left\"\n)}\nhourly_data[\"temperature_2m\"] = hourly_temperature_2m\nhourly_data[\"precipitation\"] = hourly_precipitation",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "hourly_rain",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "hourly_rain = hourly.Variables(2).ValuesAsNumpy()\nhourly_data = {\"date\": pd.date_range(\n\tstart = pd.to_datetime(hourly.Time(), unit = \"s\"),\n\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\"),\n\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n\tinclusive = \"left\"\n)}\nhourly_data[\"temperature_2m\"] = hourly_temperature_2m\nhourly_data[\"precipitation\"] = hourly_precipitation\nhourly_data[\"rain\"] = hourly_rain",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "hourly_data",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "hourly_data = {\"date\": pd.date_range(\n\tstart = pd.to_datetime(hourly.Time(), unit = \"s\"),\n\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\"),\n\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n\tinclusive = \"left\"\n)}\nhourly_data[\"temperature_2m\"] = hourly_temperature_2m\nhourly_data[\"precipitation\"] = hourly_precipitation\nhourly_data[\"rain\"] = hourly_rain\nhourly_dataframe = pd.DataFrame(data = hourly_data)",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "\tstart",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "\tstart = pd.to_datetime(hourly.Time(), unit = \"s\"),\n\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\"),\n\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n\tinclusive = \"left\"\n)}\nhourly_data[\"temperature_2m\"] = hourly_temperature_2m\nhourly_data[\"precipitation\"] = hourly_precipitation\nhourly_data[\"rain\"] = hourly_rain\nhourly_dataframe = pd.DataFrame(data = hourly_data)\nprint(hourly_dataframe)",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "\tend",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\"),\n\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n\tinclusive = \"left\"\n)}\nhourly_data[\"temperature_2m\"] = hourly_temperature_2m\nhourly_data[\"precipitation\"] = hourly_precipitation\nhourly_data[\"rain\"] = hourly_rain\nhourly_dataframe = pd.DataFrame(data = hourly_data)\nprint(hourly_dataframe)",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "\tfreq",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n\tinclusive = \"left\"\n)}\nhourly_data[\"temperature_2m\"] = hourly_temperature_2m\nhourly_data[\"precipitation\"] = hourly_precipitation\nhourly_data[\"rain\"] = hourly_rain\nhourly_dataframe = pd.DataFrame(data = hourly_data)\nprint(hourly_dataframe)",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "\tinclusive",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "\tinclusive = \"left\"\n)}\nhourly_data[\"temperature_2m\"] = hourly_temperature_2m\nhourly_data[\"precipitation\"] = hourly_precipitation\nhourly_data[\"rain\"] = hourly_rain\nhourly_dataframe = pd.DataFrame(data = hourly_data)\nprint(hourly_dataframe)",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "hourly_data[\"temperature_2m\"]",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "hourly_data[\"temperature_2m\"] = hourly_temperature_2m\nhourly_data[\"precipitation\"] = hourly_precipitation\nhourly_data[\"rain\"] = hourly_rain\nhourly_dataframe = pd.DataFrame(data = hourly_data)\nprint(hourly_dataframe)",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "hourly_data[\"precipitation\"]",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "hourly_data[\"precipitation\"] = hourly_precipitation\nhourly_data[\"rain\"] = hourly_rain\nhourly_dataframe = pd.DataFrame(data = hourly_data)\nprint(hourly_dataframe)",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "hourly_data[\"rain\"]",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "hourly_data[\"rain\"] = hourly_rain\nhourly_dataframe = pd.DataFrame(data = hourly_data)\nprint(hourly_dataframe)",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "hourly_dataframe",
        "kind": 5,
        "importPath": "Data_Analysis.4-API.Teoría.prueba",
        "description": "Data_Analysis.4-API.Teoría.prueba",
        "peekOfCode": "hourly_dataframe = pd.DataFrame(data = hourly_data)\nprint(hourly_dataframe)",
        "detail": "Data_Analysis.4-API.Teoría.prueba",
        "documentation": {}
    },
    {
        "label": "run_checks",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "description": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "peekOfCode": "def run_checks(raise_exc=False):\n    \"\"\"\n    Comprueba que los paquetes que necesitamos están instalados y que la versión de Python es buena.\n    Parámetros\n    ----------\n    raise_exc : bool, por defecto ``False``\n        Si se lanza una excepción si alguno de los paquetes no\n        no cumple los requisitos (usado para GitHub Action).\n    \"\"\"\n    failures = []",
        "detail": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "documentation": {}
    },
    {
        "label": "script_dir",
        "kind": 5,
        "importPath": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "description": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "peekOfCode": "script_dir = os.path.dirname(os.path.abspath(__file__))\n# Cambia el directorio de trabajo al directorio del script\nos.chdir(script_dir)\nOK = '\\x1b[42m[ OK ]\\x1b[0m'\nFAIL = '\\x1b[41m[FAIL]\\x1b[0m'\ngithub_package_pattern = re.compile(r'(?:\\/)([\\w*\\-*]*)(?:\\.git)')\ndef run_checks(raise_exc=False):\n    \"\"\"\n    Comprueba que los paquetes que necesitamos están instalados y que la versión de Python es buena.\n    Parámetros",
        "detail": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "documentation": {}
    },
    {
        "label": "OK",
        "kind": 5,
        "importPath": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "description": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "peekOfCode": "OK = '\\x1b[42m[ OK ]\\x1b[0m'\nFAIL = '\\x1b[41m[FAIL]\\x1b[0m'\ngithub_package_pattern = re.compile(r'(?:\\/)([\\w*\\-*]*)(?:\\.git)')\ndef run_checks(raise_exc=False):\n    \"\"\"\n    Comprueba que los paquetes que necesitamos están instalados y que la versión de Python es buena.\n    Parámetros\n    ----------\n    raise_exc : bool, por defecto ``False``\n        Si se lanza una excepción si alguno de los paquetes no",
        "detail": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "documentation": {}
    },
    {
        "label": "FAIL",
        "kind": 5,
        "importPath": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "description": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "peekOfCode": "FAIL = '\\x1b[41m[FAIL]\\x1b[0m'\ngithub_package_pattern = re.compile(r'(?:\\/)([\\w*\\-*]*)(?:\\.git)')\ndef run_checks(raise_exc=False):\n    \"\"\"\n    Comprueba que los paquetes que necesitamos están instalados y que la versión de Python es buena.\n    Parámetros\n    ----------\n    raise_exc : bool, por defecto ``False``\n        Si se lanza una excepción si alguno de los paquetes no\n        no cumple los requisitos (usado para GitHub Action).",
        "detail": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "documentation": {}
    },
    {
        "label": "github_package_pattern",
        "kind": 5,
        "importPath": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "description": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "peekOfCode": "github_package_pattern = re.compile(r'(?:\\/)([\\w*\\-*]*)(?:\\.git)')\ndef run_checks(raise_exc=False):\n    \"\"\"\n    Comprueba que los paquetes que necesitamos están instalados y que la versión de Python es buena.\n    Parámetros\n    ----------\n    raise_exc : bool, por defecto ``False``\n        Si se lanza una excepción si alguno de los paquetes no\n        no cumple los requisitos (usado para GitHub Action).\n    \"\"\"",
        "detail": "Data_Analysis.Analisis_de_datos.ch_01.check_environment",
        "documentation": {}
    },
    {
        "label": "window_calc",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.ch_04.window_calc",
        "description": "Data_Analysis.Analisis_de_datos.ch_04.window_calc",
        "peekOfCode": "def window_calc(df, func, agg_dict, *args, **kwargs):\n  \"\"\"\n    Ejecuta un cálculo de ventana de su elección en un objeto `DataFrame`.\n    Parámetros:\n        - df: El objeto `DataFrame` sobre el que ejecutar el cálculo.\n        - func: El método de cálculo de la ventana que toma `df`\n          como primer argumento.\n        - agg_dict: Información a pasar a `agg()`, puede ser un\n          diccionario que asigna las columnas a la función\n          a usar, un nombre de cadena para la función,",
        "detail": "Data_Analysis.Analisis_de_datos.ch_04.window_calc",
        "documentation": {}
    },
    {
        "label": "hex_to_rgb_color_list",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.ch_06.color_utils",
        "description": "Data_Analysis.Analisis_de_datos.ch_06.color_utils",
        "peekOfCode": "def hex_to_rgb_color_list(colors):\n    \"\"\"\n    Toma un color o una lista de colores en código hexadecimal y los convierte\n    a colores RGB en el rango [0,1].\n    Parámetros:\n        - Colores: Color o lista de cadenas de color del formato\n                  #FFF' o '#FFFFFF'.\n    Devuelve:\n        El color o lista de colores en representación RGB.\n    \"\"\"",
        "detail": "Data_Analysis.Analisis_de_datos.ch_06.color_utils",
        "documentation": {}
    },
    {
        "label": "blended_cmap",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.ch_06.color_utils",
        "description": "Data_Analysis.Analisis_de_datos.ch_06.color_utils",
        "peekOfCode": "def blended_cmap(rgb_color_list):\n    \"\"\"\n    Creado un mapa de color que mezcla de un color a otro.\n    Parámetros:\n        - rgb_color_list: Una lista de colores representados como [R, G, B]\n          en el rango [0, 1], como [[0, 0, 0], [1, 1, 1]\n          para el blanco y el negro, respectivamente.\n    Devuelve:\n        Un objeto matplotlib `ListedColormap`.\n    \"\"\"",
        "detail": "Data_Analysis.Analisis_de_datos.ch_06.color_utils",
        "documentation": {}
    },
    {
        "label": "draw_cmap",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.ch_06.color_utils",
        "description": "Data_Analysis.Analisis_de_datos.ch_06.color_utils",
        "peekOfCode": "def draw_cmap(cmap, values=np.array([[0, 1]]), **kwargs):\n    \"\"\"\n    Dibuja una barra de colores para visualizar un mapa de colores.\n    Parámetros:\n        - cmap: Un mapa de colores matplotlib\n        - valores: Los valores a utilizar para el colormap, por defecto [0, 1]\n        - kwargs: Argumentos de palabra clave para pasar a `plt.colorbar()`.\n    Devuelve:\n        Un objeto matplotlib `Colorbar`, que puede guardar con:\n        `plt.savefig(<nombre_archivo>, bbox_inches='tight')`",
        "detail": "Data_Analysis.Analisis_de_datos.ch_06.color_utils",
        "documentation": {}
    },
    {
        "label": "reg_resid_plots",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.ch_06.viz",
        "description": "Data_Analysis.Analisis_de_datos.ch_06.viz",
        "peekOfCode": "def reg_resid_plots(data):\n    \"\"\"\n    Usando `seaborn`, traza los gráficos de regresión y residuos\n    lado a lado para cada permutación de 2 columnas en los datos.\n    Parámetros:\n        - Datos: Un `pandas.DataFrame`.\n    Devuelve:\n        Un objeto `Axes` de matplotlib.\n    \"\"\"\n    num_cols = data.shape[1]",
        "detail": "Data_Analysis.Analisis_de_datos.ch_06.viz",
        "documentation": {}
    },
    {
        "label": "std_from_mean_kde",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.ch_06.viz",
        "description": "Data_Analysis.Analisis_de_datos.ch_06.viz",
        "peekOfCode": "def std_from_mean_kde(data):\n    \"\"\"\n    Trazar el KDE junto con las líneas verticales de referencia\n    para cada desviación estándar de la media.\n    Parámetros:\n        - Datos: `pandas.Series` con datos numéricos\n    Devuelve:\n        Objeto `Axes` de Matplotlib.\n    \"\"\"\n    mean_mag, std_mean = data.mean(), data.std()",
        "detail": "Data_Analysis.Analisis_de_datos.ch_06.viz",
        "documentation": {}
    },
    {
        "label": "support_and_resistance",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "peekOfCode": "def support_and_resistance():\n    \"\"\"Mostrar muestra de soporte y resistencia para las acciones de Netflix en 2018\"\"\"\n    reader = stock_analysis.StockReader('2018-01-01', '2018-12-31')\n    # obtener datos de Netflix\n    nflx = reader.get_ticker_data('NFLX')\n    # trazar la evolución del precio de cierre a lo largo del tiempo\n    ax = stock_analysis.StockVisualizer(nflx).evolution_over_time(\n        'close', figsize=(15, 3), legend=False, color=BLUE,\n        title='Comprender el soporte y la resistencia'\n    )",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "documentation": {}
    },
    {
        "label": "random_walk_stock_comparison",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "peekOfCode": "def random_walk_stock_comparison(df, choices=[-1, 1], probs=[0.5, 0.5], seed=2):\n    \"\"\"\n    Modela un paseo aleatorio a partir del primer precio de cierre de una acción en el marco de datos.\n    Muestra 3 paseos aleatorios y los datos reales en subtrazados asignados aleatoriamente.\n    ¿Puedes encontrar los datos reales?\n    Parámetros:\n        - df: El marco de datos de las acciones reales.\n        - opciones: Las opciones de tamaños de paso, por defecto [-1, 1].\n        - probs: La probabilidad de obtener cada tamaño de paso,\n                 por defecto [0.5, 0.5]. Debe tener el mismo",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "documentation": {}
    },
    {
        "label": "RED",
        "kind": 5,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "peekOfCode": "RED = '#B30000'\nGREEN = '#5BC95B'\nBLUE = '#00B3B3'\ndef support_and_resistance():\n    \"\"\"Mostrar muestra de soporte y resistencia para las acciones de Netflix en 2018\"\"\"\n    reader = stock_analysis.StockReader('2018-01-01', '2018-12-31')\n    # obtener datos de Netflix\n    nflx = reader.get_ticker_data('NFLX')\n    # trazar la evolución del precio de cierre a lo largo del tiempo\n    ax = stock_analysis.StockVisualizer(nflx).evolution_over_time(",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "documentation": {}
    },
    {
        "label": "GREEN",
        "kind": 5,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "peekOfCode": "GREEN = '#5BC95B'\nBLUE = '#00B3B3'\ndef support_and_resistance():\n    \"\"\"Mostrar muestra de soporte y resistencia para las acciones de Netflix en 2018\"\"\"\n    reader = stock_analysis.StockReader('2018-01-01', '2018-12-31')\n    # obtener datos de Netflix\n    nflx = reader.get_ticker_data('NFLX')\n    # trazar la evolución del precio de cierre a lo largo del tiempo\n    ax = stock_analysis.StockVisualizer(nflx).evolution_over_time(\n        'close', figsize=(15, 3), legend=False, color=BLUE,",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "documentation": {}
    },
    {
        "label": "BLUE",
        "kind": 5,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "peekOfCode": "BLUE = '#00B3B3'\ndef support_and_resistance():\n    \"\"\"Mostrar muestra de soporte y resistencia para las acciones de Netflix en 2018\"\"\"\n    reader = stock_analysis.StockReader('2018-01-01', '2018-12-31')\n    # obtener datos de Netflix\n    nflx = reader.get_ticker_data('NFLX')\n    # trazar la evolución del precio de cierre a lo largo del tiempo\n    ax = stock_analysis.StockVisualizer(nflx).evolution_over_time(\n        'close', figsize=(15, 3), legend=False, color=BLUE,\n        title='Comprender el soporte y la resistencia'",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.finance_viz",
        "documentation": {}
    },
    {
        "label": "low_med_high_bins_viz",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "peekOfCode": "def low_med_high_bins_viz(data, column, ylabel, title, figsize=(15, 3)):\n    \"\"\"Visualiza los bins de igual anchura bajo, medio y alto.\"\"\"\n    ax = data.plot(y=column, figsize=figsize, color='black', title=title)\n    xlims = ax.get_xlim()\n    for bin_name, hatch, bounds in zip(\n        ['low', 'med', 'high'],\n        ['///', '', '\\\\\\\\\\\\'],\n        pd.cut(data[column], bins=3).unique().categories.values\n    ):\n        plt.axhspan(bounds.left, bounds.right, alpha=0.2, label=bin_name, hatch=hatch, color='black')",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "documentation": {}
    },
    {
        "label": "quartile_bins_viz",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "peekOfCode": "def quartile_bins_viz(data, column, ylabel, title, figsize=(15, 8)):\n    \"\"\"Visualizar intervalos de cuartiles.\"\"\"\n    ax = data.plot(y=column, figsize=figsize, color='black', title=title)\n    xlims = ax.get_xlim()\n    for bin_name, hatch, bounds in zip(\n        [r'$Q_1$', r'$Q_2$', r'$Q_3$', r'$Q_4$'],\n        ['\\\\\\\\\\\\', '', '///', '||||'],\n        pd.qcut(data.volume, q=4).unique().categories.values\n    ):\n        plt.axhspan(bounds.left, bounds.right, alpha=0.2, label=bin_name, hatch=hatch, color='black')",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "documentation": {}
    },
    {
        "label": "resampling_example",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "peekOfCode": "def resampling_example():\n    \"\"\"Muestra los datos de antes y después del remuestreo a nivel de minutos a nivel diario\"\"\"\n    np.random.seed(0)\n    index = pd.date_range('2018-01-01', freq='T', periods=365*24*60)\n    raw = pd.DataFrame(\n        np.random.uniform(0, 10, size=index.shape[0]), index=index\n    )\n    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n    raw.plot(legend=False, ax=axes[0], title='raw data')\n    raw.resample('1D').sum().plot(legend=False, ax=axes[1], title='daily totals')",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "documentation": {}
    },
    {
        "label": "elliptical_orbit",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "peekOfCode": "def elliptical_orbit():\n    \"\"\"Dibuja un ejemplo de planeta con una órbita elíptica alrededor de su estrella\"\"\"\n    fig, axes = plt.subplots(1, 1)\n    orbit = Ellipse(xy=(0, 0), width=2, height=1.5, facecolor='lightblue')\n    axes.add_artist(orbit)\n    axes.plot([-1, 0], [0, 0])\n    axes.annotate(\n        'semi-major axis', \n        xy=(-0.5, 0), \n        xytext=(-0.8, -0.2), ",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "documentation": {}
    },
    {
        "label": "market_segmentation_cluster_example",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "peekOfCode": "def market_segmentation_cluster_example():\n    \"\"\"Muestre un ejemplo de conglomerados de segmentación del mercado.\"\"\"\n    df = pd.read_csv(pkg_resources.resource_stream(__name__, 'data/market_segmentation_cluster_example.csv'))\n    model = KMeans(3, random_state=2).fit(df)\n    ax = sns.scatterplot(\n        x=df.products_viewed, \n        y=df.products_purchased, \n        hue=model.labels_, \n        palette=sns.color_palette('colorblind', n_colors=3)\n    )",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.misc_viz",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "peekOfCode": "def confusion_matrix():\n    \"\"\"Crear una ayuda visual para comprender la matriz de confusión\"\"\"\n    ax = sns.heatmap(\n        np.array([[1, 0], [0, 1]]), cbar=False, cmap=ListedColormap(['whitesmoke', 'lightgray']),\n        annot=np.array([\n            ['TP\\n(True Positive)', 'FP\\n(False Positive)'], \n            ['FN\\n(False Negative)', 'TN\\n(True Negative)']\n        ]), fmt=\"\", annot_kws={'size': 15, 'weight': 'bold'}\n    )\n    ax.set_xticklabels([True, False])",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "documentation": {}
    },
    {
        "label": "portion_of_confusion_matrix_considered",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "peekOfCode": "def portion_of_confusion_matrix_considered(metrics):\n    \"\"\"Mostrar la parte de la matriz de confusión considerada para un par de métricas.\"\"\"\n    if not isinstance(metrics, set):\n        metrics = set(metrics)\n    if metrics == {'precision', 'recall'}:\n        data = [\n            ['precision + recall', 'precision'], \n            ['recall', 'not considered']\n        ]\n    elif metrics == {'sensitivity', 'specificity'}:",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "documentation": {}
    },
    {
        "label": "logistic_sigmoid",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "peekOfCode": "def logistic_sigmoid():\n    \"\"\"Mostrar el gráfico sigmoide logístico\"\"\"\n    x = np.linspace(-10, 10)\n    y = 1. / (1. + np.exp(-x))\n    fig = plt.plot(x, y)[0].figure\n    plt.title('Función Logística Sigmoide')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    return fig.axes\ndef roc_curve():",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "peekOfCode": "def roc_curve():\n    \"\"\"Mostrar curvas ROC de ejemplo.\"\"\"\n    data = pd.read_csv(pkg_resources.resource_stream(__name__, 'data/sample_roc_curves.csv'))\n    ax = sns.lineplot(\n        data=data, hue='label', x='x', y='y', palette='Greens'\n    )\n    ax.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n    # formatting \n    ax.set_title('Curvas ROC de muestra')\n    ax.set_xlabel('Tasa de falsos positivos (FPR)')",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "documentation": {}
    },
    {
        "label": "isolation_forest",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "peekOfCode": "def isolation_forest():\n    \"\"\"Muestra un ejemplo de un solo árbol en un bosque aislado.\"\"\"\n    df = pd.DataFrame({\n        'feature_1': [0, 1, 2, 8, 3.5, 2, 3], \n        'feature_2': [1, 2, 1.5, 0.25, 0.73, 1, 2]\n    })\n    fig = plt.figure(figsize=(20, 30))\n    grid_dims = (6, 8)\n    axes = []\n    # datos originales",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "documentation": {}
    },
    {
        "label": "bias_variance_tradeoff",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "peekOfCode": "def bias_variance_tradeoff():\n    \"\"\"Crear subparcelas para ilustrar el equilibrio entre sesgo y varianza\"\"\"\n    np.random.seed(5)\n    x = np.linspace(start=-1, stop=0.25, num=20)\n    y = x**2 + np.random.uniform(-0.25, 0.25, size=20)\n    fig, axes = plt.subplots(1, 3, figsize=(15, 3))\n    for ax in axes:\n        ax.plot(x, y, 'bo')\n        ax.set_xlabel('x')\n        ax.set_ylabel('y')",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.ml_viz",
        "documentation": {}
    },
    {
        "label": "show_distributions",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.sim_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.sim_viz",
        "peekOfCode": "def show_distributions():\n    \"\"\"Genera un gráfico para cada una de las distribuciones utilizadas en la simulación.\"\"\"\n    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n    axes = axes.flatten()\n    fig.delaxes(axes[-2])\n    # distribución triangular definida por el mínimo (a), el máximo (b) y la moda\n    a, b, mode = 1.5, 5, 2.75\n    peak = 2 / (b - a)# peak of PDF is at 2/(b-a)\n    axes[0].plot([a, mode, b], [0, peak, 0])\n    axes[0].set_title('Triangular PDF')",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.sim_viz",
        "documentation": {}
    },
    {
        "label": "anscombes_quartet",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def anscombes_quartet(r_squared=False):\n    \"\"\"Traza el Cuarteto de Anscombe junto con estadísticas resumidas.\"\"\"\n    # obtener datos\n    anscombe = sns.load_dataset('anscombe').groupby('dataset')\n    # definir subtramas y títulos\n    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n    axes = axes.flatten()\n    titles = ['linear', 'non-linear', 'linear with outlier', 'vertical with outlier']\n    for ax, (group_name, group_data), title in zip(axes, anscombe, titles):\n        # obtener x, y",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "datasaurus_dozen",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def datasaurus_dozen():\n    \"\"\"\n    Mostrar el conjunto de datos Datasaurus Dozen\n    Puesto original de Datasaurus: http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html\n    Docena de Datasaurus: https://www.autodeskresearch.com/publications/samestats\n    \"\"\"\n    df = pd.read_csv(pkg_resources.resource_stream(__name__, 'data/DatasaurusDozen.tsv'), sep='\\t')\n    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n    axes = axes.flatten()\n    for spine in axes[0].spines:",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "cdf_example",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def cdf_example():\n    \"\"\"Subparcelas para entender la FCD\"\"\"\n    data = _non_symmetric_data()\n    ecdf = ECDF(data)\n    fig, axes = plt.subplots(1, 3, figsize=(15, 3))\n    for ax in axes:\n        ax.plot(ecdf.x, ecdf.y)\n        ax.set_xlabel('x')\n        ax.set_ylabel('F(x)')\n    # inferior o igual al 50",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "common_dists",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def common_dists():\n    \"\"\"Mostrar algunas distribuciones de uso común.\"\"\"\n    # preparar los subplots\n    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n    axes = axes.flatten()\n    # gaussiana\n    mu, sigma = 0, 1\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    axes[0].plot(x, norm.pdf(x, mu, sigma))\n    axes[0].set_title('Gaussian PDF')",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "correlation_coefficient_examples",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def correlation_coefficient_examples():\n    \"\"\"Muestra algunos ejemplos de gráficos de dispersión con coeficientes de correlación.\"\"\"\n    # datos de partida\n    np.random.seed(0)\n    x = np.random.normal(size=100)\n    y = np.random.normal(size=100)\n    # crear subplots\n    fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n    # ninguna correlación\n    axes[0].scatter(x, y)",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "different_modal_plots",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def different_modal_plots():\n    \"\"\"Mostrar distribuciones de ejemplo unimodales, bimodales y multimodales.\"\"\"\n    # detalles de distribución\n    x = np.linspace(-4, 4, 500)\n    loc1, scale1, size1 = (-2, 0.75, 150)\n    loc2, scale2, size2 = (3, 0.5, 50)\n    loc3, scale3, size3 = (0.4, 1, 150)\n    # crear subplots\n    fig, axes = plt.subplots(1, 3, figsize=(15, 3))\n    # gráfico unimodal",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "effect_of_std_dev",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def effect_of_std_dev():\n    \"\"\"Mostrar dos distribuciones normales con diferentes desviaciones estándar.\"\"\"\n    np.random.seed(0)\n    data = pd.DataFrame({\n        'σ = 0.5': np.random.normal(scale=0.5, size=1000),\n        'σ = 2': np.random.normal(scale=2, size=1000)\n    })\n    ax = data.plot(kind='density', title='Diferentes desviaciones típicas de la población', figsize=(5, 2), colormap='brg')\n    plt.xlabel('x')\n    _despine(ax)",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "example_boxplot",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def example_boxplot():\n    \"\"\"Generar un gráfico de caja de ejemplo.\"\"\"\n    non_symmetric = _non_symmetric_data()\n    # hallar los cuartiles y el iqr\n    q1_y, median_y, q3_y = non_symmetric.quantile([0.25, 0.5, 0.75])\n    iqr = q3_y - q1_y\n    # crear una boxplot\n    ax = non_symmetric.plot(kind='box', figsize=(6, 6), title='Box plot')\n    # etiquetar la caja\n    ax.annotate('median', xy=(0.945, median_y + 2))",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "example_histogram",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def example_histogram():\n    \"\"\"Generar un histograma de ejemplo.\"\"\"\n    non_symmetric = _non_symmetric_data()\n    # obtener bins\n    bins = np.histogram_bin_edges(non_symmetric)\n    # trazar los datos\n    ax = non_symmetric.plot(\n        kind='hist', legend=False, figsize=(15, 3),\n        title=f'Histograma con 10 intervalos (each of width {bins[1] - bins[0]:.2f})'\n    )",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "example_kde",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def example_kde():\n    \"\"\"Generar un KDE de ejemplo.\"\"\"\n    non_symmetric = _non_symmetric_data()\n    # plot the data\n    ax = non_symmetric.plot(\n        kind='kde', legend=False, figsize=(15, 3), \n        title='Estimación de la densidad del núcleo', bw_method=0.1, ylim=(0, 0.02)\n    )\n    ax.set_xlabel('x')\n    # encontrar medidas de tendencia central",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "example_regression",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def example_regression():\n    \"\"\"Mostrar ejemplo de regresión.\"\"\"\n    # generar datos\n    np.random.seed(0)\n    ice_cream_sales = pd.DataFrame({\n        'temps': np.linspace(20, 40, num=30),\n        'sales': np.abs(np.append(np.arange(2, 22), np.arange(22, 32)) + np.random.randint(-10, 10, size=30))\n    })\n    # hacer el diagrama de dispersión\n    ax = ice_cream_sales.plot(",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "example_scatter_plot",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def example_scatter_plot():\n    \"\"\"Mostrar ejemplo de gráfico de dispersión.\"\"\"\n    # generar datos\n    np.random.seed(0)\n    ice_cream_sales = pd.DataFrame({\n        'temps': np.linspace(20, 40, num=30),\n        'sales': np.abs(np.append(np.arange(2, 22), np.arange(22, 32)) + np.random.randint(-10, 10, size=30))\n    })\n    # hacer el diagrama de dispersión\n    ax = ice_cream_sales.plot(",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "hist_and_kde",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def hist_and_kde():\n    \"\"\"Mostrar histograma con KDE.\"\"\"\n    # obtener datos\n    data = _non_symmetric_data()\n    # trazar histograma y KDE\n    ax = data.plot(kind='hist', density=True, bins=12, alpha=0.5, title='Estimación de la distribución', figsize=(15, 3))\n    data.plot(kind='kde', ax=ax, color='blue').set_xlabel('x')\n    _despine(ax)\n    return ax\ndef non_linear_relationships():",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "non_linear_relationships",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def non_linear_relationships():\n    \"\"\"Representar gráficamente datos logarítmicos y exponenciales junto con los coeficientes de correlación.\"\"\"\n    # crear subplots\n    fig, axes = plt.subplots(1, 2, figsize=(12, 3))\n    # trazado logarítmico\n    log_x = np.linspace(0.01, 10)\n    log_y = np.log(log_x)\n    axes[0].scatter(log_x, log_y)\n    axes[0].set_title(f'ρ = {np.round(np.corrcoef(log_x, log_y)[0][1], 2):.2f}')\n    # trazado exponencial",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "skew_examples",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def skew_examples():\n    \"\"\"Visualiza distribuciones a la izquierda, a la derecha y sin sesgo.\"\"\"\n    # crear subplots\n    fig, ax = plt.subplots(1, 3, figsize=(20, 4))\n    # determina skew\n    a = 4\n    # buscar estadísticas para la anotación\n    mean_skew_val = skewnorm.mean(a)\n    median_skew_val = skewnorm.median(a)\n    # obtener datos x donde PDF tiene valor",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "time_series_decomposition_example",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "peekOfCode": "def time_series_decomposition_example():\n    \"\"\"Mostrar un ejemplo de descomposición de series temporales.\"\"\"\n    # generar una serie temporal aleatoria\n    np.random.seed(0)\n    ts = pd.DataFrame({'timestamp' : pd.date_range('2018-01-01', periods=365, freq='D')})\n    for i, drift, seasonality, noise in zip(\n        ts.index, \n        np.linspace(0, 1, num=365), \n        itertools.cycle(np.append(np.linspace(0, np.pi, num=25), np.linspace(np.pi, 0, num=25, endpoint=False))),\n        np.random.uniform(-10, 10, size=365)",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.stats_viz",
        "documentation": {}
    },
    {
        "label": "make_grayscale",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.utils",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.utils",
        "peekOfCode": "def make_grayscale(filepath, save=False):\n    \"\"\"Convierte un archivo de imagen a escala de grises y, opcionalmente, lo guarda en `save`\"\"\"\n    img = Image.open(filepath).convert('LA')\n    if save:\n        img.save(save)\n    return img\ndef edit_image(filepath, replacements, save=False):\n    \"\"\"\n    Reemplaza los colores de la imagen especificada píxel a píxel.\n    Parámetros:",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.utils",
        "documentation": {}
    },
    {
        "label": "edit_image",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.utils",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.utils",
        "peekOfCode": "def edit_image(filepath, replacements, save=False):\n    \"\"\"\n    Reemplaza los colores de la imagen especificada píxel a píxel.\n    Parámetros:\n        - filepath: La ruta a la imagen\n        - reemplazos: Un diccionario cuyas claves son\n                        tuplas de color RGBA a reemplazar y\n                        los valores son las sustituciones\n        - guardar: Si desea guardar el archivo de nuevo a la ruta de archivo.\n    Devuelve:",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.utils",
        "documentation": {}
    },
    {
        "label": "save_plot",
        "kind": 2,
        "importPath": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.utils",
        "description": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.utils",
        "peekOfCode": "def save_plot(file):\n    \"\"\"Guardar la cifra actual.\"\"\"\n    plt.savefig(file, dpi=300, bbox_inches='tight')",
        "detail": "Data_Analysis.Analisis_de_datos.visual-aids.visual_aids.utils",
        "documentation": {}
    },
    {
        "label": "home",
        "kind": 2,
        "importPath": "Data_Engineer.Flask.Practica_flask.app",
        "description": "Data_Engineer.Flask.Practica_flask.app",
        "peekOfCode": "def home():\n    \"\"\"Render the home page.\"\"\"\n    return render_template('index.html')\n@app.route('/predict', methods=['GET', 'POST'])\ndef predict():\n    \"\"\"Handle prediction requests.\"\"\"\n    if request.method == 'POST':\n        try:\n            # Get user input and convert to floats\n            sepal_length = float(request.form['sepal_length'])",
        "detail": "Data_Engineer.Flask.Practica_flask.app",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "Data_Engineer.Flask.Practica_flask.app",
        "description": "Data_Engineer.Flask.Practica_flask.app",
        "peekOfCode": "def predict():\n    \"\"\"Handle prediction requests.\"\"\"\n    if request.method == 'POST':\n        try:\n            # Get user input and convert to floats\n            sepal_length = float(request.form['sepal_length'])\n            sepal_width = float(request.form['sepal_width'])\n            petal_length = float(request.form['petal_length'])\n            petal_width = float(request.form['petal_width'])\n            # Validate input (optional)",
        "detail": "Data_Engineer.Flask.Practica_flask.app",
        "documentation": {}
    },
    {
        "label": "TEMPLATE_DIR",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.app",
        "description": "Data_Engineer.Flask.Practica_flask.app",
        "peekOfCode": "TEMPLATE_DIR = os.path.join(os.path.dirname(__file__), 'templates')\nSTATIC_DIR = os.path.join(os.path.dirname(__file__), 'static')\nIRIS_LABELS = {1: \"Iris-setosa\", 2: \"Iris-versicolor\", 3: \"Iris-virginica\"}\n# Load the model\nmodel_file = open('model.pkl', 'rb')\nmodel = joblib.load(model_file)\n# Create the Flask app\napp = Flask(__name__, template_folder=TEMPLATE_DIR, static_folder=STATIC_DIR)\n@app.route('/')\ndef home():",
        "detail": "Data_Engineer.Flask.Practica_flask.app",
        "documentation": {}
    },
    {
        "label": "STATIC_DIR",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.app",
        "description": "Data_Engineer.Flask.Practica_flask.app",
        "peekOfCode": "STATIC_DIR = os.path.join(os.path.dirname(__file__), 'static')\nIRIS_LABELS = {1: \"Iris-setosa\", 2: \"Iris-versicolor\", 3: \"Iris-virginica\"}\n# Load the model\nmodel_file = open('model.pkl', 'rb')\nmodel = joblib.load(model_file)\n# Create the Flask app\napp = Flask(__name__, template_folder=TEMPLATE_DIR, static_folder=STATIC_DIR)\n@app.route('/')\ndef home():\n    \"\"\"Render the home page.\"\"\"",
        "detail": "Data_Engineer.Flask.Practica_flask.app",
        "documentation": {}
    },
    {
        "label": "IRIS_LABELS",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.app",
        "description": "Data_Engineer.Flask.Practica_flask.app",
        "peekOfCode": "IRIS_LABELS = {1: \"Iris-setosa\", 2: \"Iris-versicolor\", 3: \"Iris-virginica\"}\n# Load the model\nmodel_file = open('model.pkl', 'rb')\nmodel = joblib.load(model_file)\n# Create the Flask app\napp = Flask(__name__, template_folder=TEMPLATE_DIR, static_folder=STATIC_DIR)\n@app.route('/')\ndef home():\n    \"\"\"Render the home page.\"\"\"\n    return render_template('index.html')",
        "detail": "Data_Engineer.Flask.Practica_flask.app",
        "documentation": {}
    },
    {
        "label": "model_file",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.app",
        "description": "Data_Engineer.Flask.Practica_flask.app",
        "peekOfCode": "model_file = open('model.pkl', 'rb')\nmodel = joblib.load(model_file)\n# Create the Flask app\napp = Flask(__name__, template_folder=TEMPLATE_DIR, static_folder=STATIC_DIR)\n@app.route('/')\ndef home():\n    \"\"\"Render the home page.\"\"\"\n    return render_template('index.html')\n@app.route('/predict', methods=['GET', 'POST'])\ndef predict():",
        "detail": "Data_Engineer.Flask.Practica_flask.app",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.app",
        "description": "Data_Engineer.Flask.Practica_flask.app",
        "peekOfCode": "model = joblib.load(model_file)\n# Create the Flask app\napp = Flask(__name__, template_folder=TEMPLATE_DIR, static_folder=STATIC_DIR)\n@app.route('/')\ndef home():\n    \"\"\"Render the home page.\"\"\"\n    return render_template('index.html')\n@app.route('/predict', methods=['GET', 'POST'])\ndef predict():\n    \"\"\"Handle prediction requests.\"\"\"",
        "detail": "Data_Engineer.Flask.Practica_flask.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.app",
        "description": "Data_Engineer.Flask.Practica_flask.app",
        "peekOfCode": "app = Flask(__name__, template_folder=TEMPLATE_DIR, static_folder=STATIC_DIR)\n@app.route('/')\ndef home():\n    \"\"\"Render the home page.\"\"\"\n    return render_template('index.html')\n@app.route('/predict', methods=['GET', 'POST'])\ndef predict():\n    \"\"\"Handle prediction requests.\"\"\"\n    if request.method == 'POST':\n        try:",
        "detail": "Data_Engineer.Flask.Practica_flask.app",
        "documentation": {}
    },
    {
        "label": "perform_cross_validation",
        "kind": 2,
        "importPath": "Data_Engineer.Flask.Practica_flask.iris",
        "description": "Data_Engineer.Flask.Practica_flask.iris",
        "peekOfCode": "def perform_cross_validation(X, y, model, cv=5):  # cv is the number of folds\n    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n    return scores.mean()\niris = load_iris()\nXall = iris.data\nyall = iris.target\nXtrain, Xtest, ytrain, ytest = train_test_split(Xall, yall, test_size=0.2)\nX = Xtrain\ny = ytrain\nmodel = KNeighborsClassifier()",
        "detail": "Data_Engineer.Flask.Practica_flask.iris",
        "documentation": {}
    },
    {
        "label": "iris",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.iris",
        "description": "Data_Engineer.Flask.Practica_flask.iris",
        "peekOfCode": "iris = load_iris()\nXall = iris.data\nyall = iris.target\nXtrain, Xtest, ytrain, ytest = train_test_split(Xall, yall, test_size=0.2)\nX = Xtrain\ny = ytrain\nmodel = KNeighborsClassifier()\nmodel.fit(Xtrain, ytrain)\naccuracy = perform_cross_validation(Xtest, ytest, model)\nprint(accuracy)",
        "detail": "Data_Engineer.Flask.Practica_flask.iris",
        "documentation": {}
    },
    {
        "label": "Xall",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.iris",
        "description": "Data_Engineer.Flask.Practica_flask.iris",
        "peekOfCode": "Xall = iris.data\nyall = iris.target\nXtrain, Xtest, ytrain, ytest = train_test_split(Xall, yall, test_size=0.2)\nX = Xtrain\ny = ytrain\nmodel = KNeighborsClassifier()\nmodel.fit(Xtrain, ytrain)\naccuracy = perform_cross_validation(Xtest, ytest, model)\nprint(accuracy)\n#scaler = StandardScaler()",
        "detail": "Data_Engineer.Flask.Practica_flask.iris",
        "documentation": {}
    },
    {
        "label": "yall",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.iris",
        "description": "Data_Engineer.Flask.Practica_flask.iris",
        "peekOfCode": "yall = iris.target\nXtrain, Xtest, ytrain, ytest = train_test_split(Xall, yall, test_size=0.2)\nX = Xtrain\ny = ytrain\nmodel = KNeighborsClassifier()\nmodel.fit(Xtrain, ytrain)\naccuracy = perform_cross_validation(Xtest, ytest, model)\nprint(accuracy)\n#scaler = StandardScaler()\n#X = scaler.fit_transform(X)",
        "detail": "Data_Engineer.Flask.Practica_flask.iris",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.iris",
        "description": "Data_Engineer.Flask.Practica_flask.iris",
        "peekOfCode": "X = Xtrain\ny = ytrain\nmodel = KNeighborsClassifier()\nmodel.fit(Xtrain, ytrain)\naccuracy = perform_cross_validation(Xtest, ytest, model)\nprint(accuracy)\n#scaler = StandardScaler()\n#X = scaler.fit_transform(X)\nypred=model.predict(Xtest)\nprint(confusion_matrix(ypred,ytest))",
        "detail": "Data_Engineer.Flask.Practica_flask.iris",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.iris",
        "description": "Data_Engineer.Flask.Practica_flask.iris",
        "peekOfCode": "y = ytrain\nmodel = KNeighborsClassifier()\nmodel.fit(Xtrain, ytrain)\naccuracy = perform_cross_validation(Xtest, ytest, model)\nprint(accuracy)\n#scaler = StandardScaler()\n#X = scaler.fit_transform(X)\nypred=model.predict(Xtest)\nprint(confusion_matrix(ypred,ytest))\nprint(accuracy_score(ypred,ytest))",
        "detail": "Data_Engineer.Flask.Practica_flask.iris",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.iris",
        "description": "Data_Engineer.Flask.Practica_flask.iris",
        "peekOfCode": "model = KNeighborsClassifier()\nmodel.fit(Xtrain, ytrain)\naccuracy = perform_cross_validation(Xtest, ytest, model)\nprint(accuracy)\n#scaler = StandardScaler()\n#X = scaler.fit_transform(X)\nypred=model.predict(Xtest)\nprint(confusion_matrix(ypred,ytest))\nprint(accuracy_score(ypred,ytest))\npickle.dump(model, open(\".\\Data_Engineer\\Flask\\Practica_flask\\model.pkl\", \"wb\"))",
        "detail": "Data_Engineer.Flask.Practica_flask.iris",
        "documentation": {}
    },
    {
        "label": "accuracy",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.iris",
        "description": "Data_Engineer.Flask.Practica_flask.iris",
        "peekOfCode": "accuracy = perform_cross_validation(Xtest, ytest, model)\nprint(accuracy)\n#scaler = StandardScaler()\n#X = scaler.fit_transform(X)\nypred=model.predict(Xtest)\nprint(confusion_matrix(ypred,ytest))\nprint(accuracy_score(ypred,ytest))\npickle.dump(model, open(\".\\Data_Engineer\\Flask\\Practica_flask\\model.pkl\", \"wb\"))",
        "detail": "Data_Engineer.Flask.Practica_flask.iris",
        "documentation": {}
    },
    {
        "label": "#scaler",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.iris",
        "description": "Data_Engineer.Flask.Practica_flask.iris",
        "peekOfCode": "#scaler = StandardScaler()\n#X = scaler.fit_transform(X)\nypred=model.predict(Xtest)\nprint(confusion_matrix(ypred,ytest))\nprint(accuracy_score(ypred,ytest))\npickle.dump(model, open(\".\\Data_Engineer\\Flask\\Practica_flask\\model.pkl\", \"wb\"))",
        "detail": "Data_Engineer.Flask.Practica_flask.iris",
        "documentation": {}
    },
    {
        "label": "#X",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Practica_flask.iris",
        "description": "Data_Engineer.Flask.Practica_flask.iris",
        "peekOfCode": "#X = scaler.fit_transform(X)\nypred=model.predict(Xtest)\nprint(confusion_matrix(ypred,ytest))\nprint(accuracy_score(ypred,ytest))\npickle.dump(model, open(\".\\Data_Engineer\\Flask\\Practica_flask\\model.pkl\", \"wb\"))",
        "detail": "Data_Engineer.Flask.Practica_flask.iris",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 2,
        "importPath": "Data_Engineer.Flask.Teoria.app",
        "description": "Data_Engineer.Flask.Teoria.app",
        "peekOfCode": "def index():\n    print('esto no funciona en la web pero si en la terminal')\n    print(app.config['BCRYPT_LOG_ROUNDS'])\n    return \"<h1>Hola Solecito!</h1>\"\n@app.route('/rodrigo')\ndef index1():\n    return \"<h1>Rodrigo estuvo aquí!</h1>\"\nprint('esto no funciona')\n@app.route(f\"/user/{app.config['BCRYPT_LOG_ROUNDS']}/<name>\")\ndef user(name):",
        "detail": "Data_Engineer.Flask.Teoria.app",
        "documentation": {}
    },
    {
        "label": "index1",
        "kind": 2,
        "importPath": "Data_Engineer.Flask.Teoria.app",
        "description": "Data_Engineer.Flask.Teoria.app",
        "peekOfCode": "def index1():\n    return \"<h1>Rodrigo estuvo aquí!</h1>\"\nprint('esto no funciona')\n@app.route(f\"/user/{app.config['BCRYPT_LOG_ROUNDS']}/<name>\")\ndef user(name):\n    return \"<h1>Hello, {}!</h1>\".format(name)\n@app.route(\"/user/<name>/<int:ind>\")\ndef index2(name, ind):\n    mylist = ['2024/03/06', 'elemento2', False, 'elemento4']\n    mydict = {'key': -ind}",
        "detail": "Data_Engineer.Flask.Teoria.app",
        "documentation": {}
    },
    {
        "label": "user",
        "kind": 2,
        "importPath": "Data_Engineer.Flask.Teoria.app",
        "description": "Data_Engineer.Flask.Teoria.app",
        "peekOfCode": "def user(name):\n    return \"<h1>Hello, {}!</h1>\".format(name)\n@app.route(\"/user/<name>/<int:ind>\")\ndef index2(name, ind):\n    mylist = ['2024/03/06', 'elemento2', False, 'elemento4']\n    mydict = {'key': -ind}\n    mytuple = (datetime.now().date().strftime('%Y/%m/%d'), None, 'tuple3', np.nan)\n    return jsonify(name=name, myindex=ind, mylist=mylist, mydict=mydict, mytuple=mytuple)\nif __name__ == '__main__':\n    app.run(debug=True,host=\"0.0.0.0\", port=8910)",
        "detail": "Data_Engineer.Flask.Teoria.app",
        "documentation": {}
    },
    {
        "label": "index2",
        "kind": 2,
        "importPath": "Data_Engineer.Flask.Teoria.app",
        "description": "Data_Engineer.Flask.Teoria.app",
        "peekOfCode": "def index2(name, ind):\n    mylist = ['2024/03/06', 'elemento2', False, 'elemento4']\n    mydict = {'key': -ind}\n    mytuple = (datetime.now().date().strftime('%Y/%m/%d'), None, 'tuple3', np.nan)\n    return jsonify(name=name, myindex=ind, mylist=mylist, mydict=mydict, mytuple=mytuple)\nif __name__ == '__main__':\n    app.run(debug=True,host=\"0.0.0.0\", port=8910)",
        "detail": "Data_Engineer.Flask.Teoria.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Teoria.app",
        "description": "Data_Engineer.Flask.Teoria.app",
        "peekOfCode": "app = Flask(__name__, instance_relative_config=True)\napp.config.from_object(\"config\")\n# app.config.from_pyfile(\"Data_Engineer/Flask/Teoria/config.py\")\n@app.route('/')\ndef index():\n    print('esto no funciona en la web pero si en la terminal')\n    print(app.config['BCRYPT_LOG_ROUNDS'])\n    return \"<h1>Hola Solecito!</h1>\"\n@app.route('/rodrigo')\ndef index1():",
        "detail": "Data_Engineer.Flask.Teoria.app",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Teoria.config",
        "description": "Data_Engineer.Flask.Teoria.config",
        "peekOfCode": "DEBUG = True # activa la depuración en Flask\nBCRYPT_LOG_ROUNDS = 12 # configuración para la extensión Flask-Bcrypt\nMAIL_FROM_EMAIL = \"micorreo@gmail.com\"",
        "detail": "Data_Engineer.Flask.Teoria.config",
        "documentation": {}
    },
    {
        "label": "BCRYPT_LOG_ROUNDS",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Teoria.config",
        "description": "Data_Engineer.Flask.Teoria.config",
        "peekOfCode": "BCRYPT_LOG_ROUNDS = 12 # configuración para la extensión Flask-Bcrypt\nMAIL_FROM_EMAIL = \"micorreo@gmail.com\"",
        "detail": "Data_Engineer.Flask.Teoria.config",
        "documentation": {}
    },
    {
        "label": "MAIL_FROM_EMAIL",
        "kind": 5,
        "importPath": "Data_Engineer.Flask.Teoria.config",
        "description": "Data_Engineer.Flask.Teoria.config",
        "peekOfCode": "MAIL_FROM_EMAIL = \"micorreo@gmail.com\"",
        "detail": "Data_Engineer.Flask.Teoria.config",
        "documentation": {}
    },
    {
        "label": "data_report",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def data_report(df):\n    # Sacamos los NOMBRES\n    cols = pd.DataFrame(df.columns.values, columns=[\"COL_N\"])\n    # Sacamos los TIPOS\n    types = pd.DataFrame(df.dtypes.values, columns=[\"DATA_TYPE\"])\n    # Sacamos los MISSINGS\n    percent_missing = round(df.isnull().sum() * 100 / len(df), 2)\n    percent_missing_df = pd.DataFrame(percent_missing.values, columns=[\"MISSINGS (%)\"])\n    # Sacamos los VALORES UNICOS\n    unicos = pd.DataFrame(df.nunique().values, columns=[\"UNIQUE_VALUES\"])",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "drop_cols",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def drop_cols(df_, max_cardi=20, max_miss=30):\n    df = df_.copy()\n    delete_col = []\n    for i in df.columns:\n        missings = df[i].isnull().sum() * 100 / len(df)\n        # Elimina por missings\n        if missings >= max_miss:\n            df.drop(i, 1, inplace=True)\n            continue\n        # Elimina por cardinalidad en variables categoricas",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "outliers_quantile",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def outliers_quantile(df, feature, param=1.5):  \n    iqr_ = iqr(df[feature], nan_policy='omit')\n    q1 = np.nanpercentile(df[feature], 25)\n    q3 = np.nanpercentile(df[feature], 75)\n    th1 = q1 - iqr_*param\n    th2 = q3 + iqr_*param\n    return df[(df[feature] >= th1) & (df[feature] <= th2)].reset_index(drop=True)\ndef outlier_meanSd(df, feature, param=3):   \n    media = df[feature].mean()\n    desEst = df[feature].std()",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "outlier_meanSd",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def outlier_meanSd(df, feature, param=3):   \n    media = df[feature].mean()\n    desEst = df[feature].std()\n    th1 = media - desEst*param\n    th2 = media + desEst*param\n    return df[((df[feature] >= th1) & (df[feature] <= th2))  | (df[feature].isnull())].reset_index(drop=True)\ndef plot_tidy_categorical(df, sel_cols, target, file_output=None):\n    \"\"\"\n    Generate bar plots for each categorical variable,\n    grouped by target variable.",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "plot_tidy_categorical",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def plot_tidy_categorical(df, sel_cols, target, file_output=None):\n    \"\"\"\n    Generate bar plots for each categorical variable,\n    grouped by target variable.\n    Parameters:\n    - df: DataFrame, the input dataset\n    - sel_cols: list, categorical variables\n    - target: str, name of the column containing the target variable\n    Returns:\n    - None (displays the plots)",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "plot_tidy",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def plot_tidy(df, sel_cols, target,file_output=None):\n    \"\"\"\n    Generate kernel density estimation (KDE) plots for each variable,\n    grouped by target variable.\n    Parameters:\n    - df: DataFrame, the input dataset\n    - sel_cols: list, variables used for clustering\n    - target: str, name of the column containing the target variable\n    Returns:\n    - None (displays the plots)",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "reduce_memory_usage",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    # Excluir las columnas de índice\n    columns_to_exclude = df.index.names if df.index.name else []\n    for col in df.columns:\n        if col in columns_to_exclude:\n            continue\n        col_type = df[col].dtypes\n        if col_type in numerics:",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "plot_kde_histogram_with_stats",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def plot_kde_histogram_with_stats(data, column_name, title, ax=None):\n    # Use provided ax or create a new subplot\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 6))\n    # KDE + Histogram\n    sns.distplot(data[column_name],fit=norm, kde=True, rug=True, ax=ax)\n    ax.set_title(f'KDE + Histogram - {title}')\n    # Verificar si la columna contiene datos numéricos\n    if pd.api.types.is_numeric_dtype(data[column_name].dtype):\n        # Calcular estadísticas solo si la columna contiene datos numéricos",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "box_violin_plot",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def box_violin_plot(data, column, title, ax=None):\n    # Use provided ax or create a new subplot\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(8, 4))\n    # Violin + Boxplot\n    sns.violinplot(data=data, x=column, inner='point', linewidth=0, saturation=0.4, orient='h', ax=ax)\n    sns.boxplot(x=column, data=data, width=0.3, boxprops={'zorder': 2}, ax=ax, orient='h', fliersize=5)\n    # Adjust the plot design\n    ax.set_title(f\"Boxplot + Violin Plot - {title}\")\n    # Get statistics",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "qq_plot",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def qq_plot(data, column_name, title,ax=None):\n    if ax is None:\n        _, ax = plt.subplots(figsize=(8, 4))\n    # Create QQ plot\n    sm.qqplot(data[column_name], line='s', ax=ax)\n    ax.set_title(f\"Quantile-Quantile Plot - {title}\")\n    plt.xlabel(\"Cuantiles teóricos\")\n    plt.ylabel(\"Cuantiles observados\")\ndef plot_distribucion(data, column_name, **kwargs):\n    title = kwargs.get('title', column_name)",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "plot_distribucion",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def plot_distribucion(data, column_name, **kwargs):\n    title = kwargs.get('title', column_name)\n    save_png, filename = kwargs.get('save_png', False), kwargs.get('filename', 'tmp.png')\n    # Create subplots with specified width ratios\n    fig, axs = plt.subplots(1, 3, figsize=(15, 6), gridspec_kw={'width_ratios': [2, 2, 1]})\n    # Loop through the plots and functions\n    for i, plot_function in enumerate([plot_kde_histogram_with_stats, box_violin_plot, qq_plot]):\n        plot_function(data, column_name, title, ax=axs[i])\n    # Adjust the layout of the subplots\n    plt.tight_layout()",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "sim_curtosis",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def sim_curtosis(data, column_name):\n    kurtosis_valor = kurtosis(data[column_name])\n    skewness_valor = skew(data[column_name])\n    if kurtosis_valor > 3:\n        kurtosis_=\"La distribución es leptocúrtica, lo que sugiere colas pesadas y picos agudos.\"\n    elif kurtosis_valor < 3:\n        kurtosis_=\"La distribución es platicúrtica, lo que sugiere colas ligeras y un pico achatado.\"\n    else:\n        kurtosis_=\"La distribución es mesocúrtica, similar a una distribución normal.\"\n    if skewness_valor > 0:",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "plot_horizontal_catplot",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def plot_horizontal_catplot(df, catcols, diccionario_columnas=None, diccionario_valores=None,\n                            save_png=False, filename='tmp.png'):\n    \"\"\"\n    Genera gráficos Seaborn para la frecuencia de valores únicos en las columnas categóricas del DataFrame.\n    Los gráficos se organizan en filas y las categorías se ordenan por porcentaje descendente.\n    El número de valores NaN o nulos se muestra en el título de cada gráfico.\n    Parameters:\n    - df: DataFrame de pandas\n    - catcols: Lista de columnas categóricas\n    - diccionario_columnas: Diccionario para decodificar nombres de columnas (opcional)",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "plot_analysis",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def plot_analysis(data, target, col):\n    col_mean = []\n    for each in data[target].unique():\n        x = data[data[target] == each]\n        mean = x[col].mean()\n        col_mean.append(mean)\n    plt.figure(figsize=(8,6))\n    plt.subplot(2,2,1)\n    plt.hist(data[col], color=\"lightgreen\")\n    plt.xlabel(col)",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "sqrt_transform",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def sqrt_transform(X):\n    return np.sqrt(X)\ndef log_transform(X):\n    return np.log1p(X)\ndef classify_distributions(df, threshold=0.05):\n    \"\"\"\n    Clasifica las distribuciones de las columnas numéricas del DataFrame en una de las siguientes categorías:\n    - 'normal': si la distribución se ajusta a una distribución normal según el test de Shapiro-Wilk.\n    - 'positive_increasing': si la distribución es estrictamente creciente positiva.\n    - 'positive_decreasing': si la distribución es estrictamente decreciente positiva.",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "log_transform",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def log_transform(X):\n    return np.log1p(X)\ndef classify_distributions(df, threshold=0.05):\n    \"\"\"\n    Clasifica las distribuciones de las columnas numéricas del DataFrame en una de las siguientes categorías:\n    - 'normal': si la distribución se ajusta a una distribución normal según el test de Shapiro-Wilk.\n    - 'positive_increasing': si la distribución es estrictamente creciente positiva.\n    - 'positive_decreasing': si la distribución es estrictamente decreciente positiva.\n    - 'rectangular': si la distribución es rectangular.\n    - 'skewed_left': si la distribución tiene sesgo a la izquierda.",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "classify_distributions",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def classify_distributions(df, threshold=0.05):\n    \"\"\"\n    Clasifica las distribuciones de las columnas numéricas del DataFrame en una de las siguientes categorías:\n    - 'normal': si la distribución se ajusta a una distribución normal según el test de Shapiro-Wilk.\n    - 'positive_increasing': si la distribución es estrictamente creciente positiva.\n    - 'positive_decreasing': si la distribución es estrictamente decreciente positiva.\n    - 'rectangular': si la distribución es rectangular.\n    - 'skewed_left': si la distribución tiene sesgo a la izquierda.\n    - 'skewed_right': si la distribución tiene sesgo a la derecha.\n    - 'bimodal': si la distribución tiene dos modas.",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "selvars_boruta",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def selvars_boruta(data,ytarget,isclass=True,n_trials=100):\n    Feature_Selector = BorutaShap(importance_measure='shap',\n                                classification=isclass)\n    Feature_Selector.fit(X=data, y=ytarget, n_trials=n_trials, random_state=0)\n    Feature_Selector.TentativeRoughFix()\n    Feature_Selector.plot(X_size=8, figsize=(20,8),\n                y_scale='log', which_features='all')\n    selvars=sorted(list(Feature_Selector.Subset().columns))\n    return selvars\nimport seaborn as sns",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "plot_confusion_matrix",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def plot_confusion_matrix(true_labels, predicted_labels):\n    \"\"\"\n    Plot a confusion matrix using true labels and predicted labels.\n    Parameters:\n    true_labels (array-like): True labels.\n    predicted_labels (array-like): Predicted labels.\n    \"\"\"\n    # Calculate the confusion matrix\n    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n    # Create a heatmap using seaborn",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "cross_validation_with_confusion_matrix",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def cross_validation_with_confusion_matrix(estimator, X, y, nsplits=10):\n    cv = StratifiedKFold(n_splits=nsplits)\n    # Perform cross-validation\n    predicted = cross_val_predict(estimator, X, y, cv=cv)\n    # Calculate confusion matrix and classification report for each fold\n    for i, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n        # Fit the estimator on training data\n        estimator.fit(X_train, y_train)",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "plot_roc_curve",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def plot_roc_curve(model, X_val, y_val):\n    # Predecir las probabilidades de las clases positivas\n    y_prob = model.predict_proba(X_val)[:, 1]\n    # Calcular la tasa de verdaderos positivos (TPR) y la tasa de falsos positivos (FPR)\n    fpr, tpr, thresholds = roc_curve(y_val, y_prob)\n    # Calcular el área bajo la curva ROC (AUC)\n    auc = roc_auc_score(y_val, y_prob)\n    # Plotear la curva ROC\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "generate_roc_auc",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def generate_roc_auc(estimator, X_train, y_train, X_val, y_val):\n    \"\"\"\n    Generate ROC curve and calculate AUC using one-vs-all technique.\n    Parameters:\n    estimator: scikit-learn estimator object\n        The classifier or regressor to use.\n    X_train: array-like, shape (n_samples, n_features)\n        The input samples for training.\n    y_train: array-like, shape (n_samples,)\n        The target values for training.",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "hyperparameter_tuning",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def hyperparameter_tuning(models, X, y, scoring='accuracy'):\n    # Almacena los resultados en un DataFrame\n    results = []\n    # Loop sobre los modelos con tqdm para mostrar una barra de progreso\n    for model_name, config in tqdm(models.items(), desc=\"Hyperparameter Tuning\"):\n        model = RandomizedSearchCV(config[\"model\"], config[\"params\"], n_iter=50, cv=5, scoring=scoring,\n                                   random_state=42)\n        model.fit(X, y)  # Ajusta el modelo con los datos de entrenamiento\n        best_params = model.best_params_\n        best_score = model.best_score_",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "perform_cross_validation",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def perform_cross_validation(models, x_train, y_train, n_splits=8, random_state=42, metric='accuracy'):\n    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n    cv_results = []\n    for name, model in models.items():\n        cv_scores = cross_val_score(model, x_train, y_train, scoring=metric, cv=kfold, n_jobs=-1)\n        cv_results.append(np.mean(cv_scores))\n    cv_df = pd.DataFrame({\"CrossVal_Score_Means\": cv_results, \"Algorithm\": list(models.keys())})\n    plt.figure(figsize=(10, 7))\n    g = sns.barplot(x=\"CrossVal_Score_Means\", y=\"Algorithm\", data=cv_df, orient=\"h\", palette='cool', \n                    edgecolor=\"black\", linewidth=1)",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    },
    {
        "label": "test_distribution_cv",
        "kind": 2,
        "importPath": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "description": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "peekOfCode": "def test_distribution_cv(dataframe, perfrac=0.01, columns=None, n_trials=10):\n    sample = X_train.sample(frac=perfrac)\n    kf = KFold(n_splits=n_trials, shuffle=True, random_state=42)\n    results = []\n    if columns is None:\n        columns = dataframe.columns\n    for column_name in columns:\n        equal_distributions = 0\n        for train_index, test_index in kf.split(dataframe):\n            train_data = dataframe.iloc[train_index]",
        "detail": "Machine_Learning.Prueba_Tecnica_Nivel.utils.utils",
        "documentation": {}
    }
]